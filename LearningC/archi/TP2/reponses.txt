// exo1_1
on fait tourner la boucle qui incrémente i tant que i est inférieur à (char)(i+1)
autrement dit, on cherche la valeur maximum que i peut prendre juste avant le débordement du type char, car à (char)(i+1),qd i est maximum, imax est supérieur à (char)(i+i),on sort donc du boucle while.

commandes:
gcc exo1_1.c
./a.out
sorties:
plus grand char positif : 127
plus grand char négatif : -128
On trouve donc imax =127 et la valeur de (char)(i+1) est de -128, la condition de la boucle n'est plus valide, on y sort et on traite les printf qui suivent.

* je précise avec (char) car je veux forcer la conversion de la valeur entier i qui suit en type char et ainsi determiner la limite supérieur du type char,
sinon, on aurais le cas i< i+1, où i est un entier qui rend la boucle while infinie, entier i est forcément inférieur à l'entier i plus un, logique...

* la valeur maximale représentée par un char est donc 127
* la valeur minimale représentée par un char est donc -128

* On a donc:
	127 valeur positif (1 à 127)
	128 valeur négatif (-128 à -1)
	1 valeur nul (0)
127+128+1=256 valeur possible
or 256=2^8 on déduit donc qu'un char est définie sur 8 bits,soit 1 octet.

//1.2
gcc exo1_2.c
./a.out
plus grand char positif : 2147483647
plus grand char négatif : -2147483648
* les valeurs max et min sont respectivement 2147483647 et -2147483648

* meme raisonnement:
	2 147 483 647*2+11 += 4 294 967 296
obase=2
4294967296
1 00000000 00000000 00000000 00000000
8*4=32 = 2^32
le type int est défini donc sur 32 bits soit 4 octets.

//1.3
gcc exo1_3.c
./a.out
taille d'un char : 8 bits  
taille d'un int : 32 bits  
taille d'un float : 32 bits 
taille d'un double : 64 bits 
taille d'un short : 16 bits 
taille d'un long : 64 bits 
taille d'un long double : 128 bits 
taille d'un unsigned int : 32 bits 
taille d'un unsigned char : 8 bits 
taille d'un unsigned short : 16 bits 
taille d'un unsigned long : 64 bits 

* on retrouve 1 et 4 pour char et int,
* nb entiers: int, float, double, short, long, long double, long double, 
pour des entiers positif on peut aussi utiliser:
unsigned int, unsigned short, unsigned long.

* nb flottants: float, double, long double.
* nb non signés: int, float, double, short, long, long double,
* nb signés: int, float, double, long double

//2
gcc exo2.c
./a.out
00000001 00000011 00000111 00001111
la calculatrice programmeur nous donne:
00001111 00000111 00000011 00000001
En la fonction nous donne en queleque sorte 252117761 mais ordre des octets sont inversé.

gcc exo2.c
./a.out
00000001 00000011 00000111 00001111 
00001111 00000111 00000011 00000001 

//2.3
signe =1 (negatif)
211 %  8 =3 <<
211 // 8 =26
26 % 8 = 2 <<
26 // 8 = 3 <<
211 deviens 323 en octal
on converti ensuite en binaire 323 chiffre par chiffre,
3->011
2->010
ce qui nous donne 1101 0011 = 1.101 0011 * 10^7
la mantisse vaut donc 101 0011 et l'exposant vaut 7
on rajoute 127 en binaire afin d'obtenir sa representation en excédent
    0000 0111
   +0111 1111
  = 1000 0110
apres vérification à la calculatrice,on a bien 134= 7+134
donc -211 est représenté par 
1 | 1000 0110 | 1010 0011 000000...

gcc exo2.c
./a.out
00000000 00000000 01010011 11000011 
11000011 01010011 00000000 00000000 << on a bien notre nombre


//2.4
gcc exo2.c
./a.out
00000000 00000000 11011011 11000000 
11000000 11011011 00000000 00000000
en cours nous avions trouvé 110.11011 avec 1 en signe et 1000 0001 en exposant


//3
gcc exo3.c
./a.out
la conversion de 00001111000001110000001100000001 en entier donne 252117761

//3.1
gcc exo3.c
./a.out
la conversion de 11111111111111111111111100101101 en entier donne -211

la conversion de 1100011111110110100001001000001 en entier donne -940145534
la conversion de 10000000000000000000000000000001 en entier donne -2147483647

  1100011 11111011 01000010 01000001
  0011100 00000100 10111101 10111111
1 0000000 00000000 00000000 00000001
Il semble bien que nous avons atteint le minimum de la valeur possible sur 32 bits.
Cf https://en.wikipedia.org/wiki/C_data_types
Long signed integer type. Capable of containing at least the [−2,147,483,647, +2,147,483,647] range;[3][4] thus, it is at least 32 bits in size.

//3.2
gcc exo3.c
./a.out
la conversion de 010100001001101110000000000000000 en entier donne 1352368128 
//on retrouve bien 1325368128 à la calculatrice
la conversion de 01111111100000000000000000000000 en entier donne 2139095040 //+infinie
la conversion de 11111111100000000000000000000000 en entier donne -8388608
//-infinie
la conversion de 01111111111111111111111111111111 en entier donne 2147483647
// nan
la conversion de 0000000000000000000000000000000 en entier donne 0
// zéro
la conversion de 00000000001100101001011100011011 en entier donne 8.009913e-307
//qui est sensé donner 4.645981E-39

//3.3
gcc exo3_3.c
./a.out
(char) c = A
(int) c = 65
c (hexadecimal) = 41
(char*) tab = ABC
(int) i = 4407873,  i (hexadecimal) = 434241
(float) f = 0.000000, f (notation scientifique) = 6.176746e-039

// on imprime le charactere stocké dans c, qui affiche la lettre A, logique

// A majuscule en code ASCII est 65ème du tableau, donc 65 en si on demande entier qui represente 'A'
cf:https://commons.wikimedia.org/wiki/File:ASCII-Table.svg

// la meme raisonnement, 65(base 10) = 41(base 16)

// ensuite nous avons 3 appels de fct bin2mem puis printf,

//la premiere nous affiche ABC, il s'agit en realité de ABC et de [Null](qui vaut rien ofc...)
bin2mem converti la chaine en 4 entiers et les stock dans le tableau,ainsi nous avons:
00000000->0
01000011->67->C
01000010->66->B
01000001->65->A
comme il s'agit d'un tableau de type char,65-67 équivaut à A,B,C

//ligne suivante, on affiche i (qui correspond à au resultat de la conversion 00000.... par bin2mem) sous format entier decimal ou hexadecimal,
(int i)=4407873 n'a pas de sens,comportement inconnue,problème due à la précision offerte par le type int en base 10 peut être,
par contre en hexadécimal on a 434241 qui correspond bien à la représentation hexadécimal du 0000...blabla  -> 0x00434241

//ligne suivante, bin2mem fait à peu près la même chose, cette fois-ci on stock le resultat dans un type float,
f=0.000000 logique, le type float affiche par défaut 6 chiffres après la virgule, sachant que votre nombre faut un truc à la puissance 10-39, c normale que la machine l'arrondi à 0.

//Enfin, l'affichage en notation scientifique est beaucoup plus précise, il affiche 6.176746e-039 qui est acceptable en vue de la taille de la variable

En conclusion, on remarque une perte de précision plus ou moins importante selon les types,
par exemple on peut forcer affichage des nombre apres la virgule avec %.18e
on obtient à l'écran alors 6.176745665838824400e-039 et voir ainsi l'arrondi

par un convertisseur on voit bien que la valeur stocké est en réalité bcp plus complex que 16 chiffres après la virgule...
https://www.h-schmidt.net/FloatConverter/IEEE754.html
6.17674566583882439686379268948487248733472204652506320440214384771414508901177242705671233125030994415283203125E-39